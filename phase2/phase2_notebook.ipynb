{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18cdec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages and data\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#import csvs to df\n",
    "nyt_stance = []\n",
    "twitter_stance = []\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    nyt_stance.append(pd.read_csv('original_csvs/nyt_stance_'+ str(i) +'.csv'))\n",
    "    twitter_stance.append(pd.read_csv('original_csvs/twitter_stance_'+ str(i) +'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2f4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN values with 'missing' for all csvs in nyt_stance\n",
    "for nyt in nyt_stance:\n",
    "    for i in list(nyt.columns[1:]):\n",
    "        nyt[i].fillna('missing', inplace=True)\n",
    "        \n",
    "for twit in twitter_stance:\n",
    "    for i in list(twit.columns[1:]):\n",
    "        twit[i].fillna('missing', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f239906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Cohen's Kappa for each pair of observers. \n",
    "# k=(p_0 - p_e)/(1 - p_e) where p_0 is empirical probability and p_e is expected agreement.\n",
    "# p_0 = num in agreement/ total\n",
    "# p_e = p_correct + p_incorrect which is:\n",
    "# = (a_correct/total * b_correct/total) + (a_incorrect/total * b_incorrect/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f1a5b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Compute Cohen's Kappa for each pair of observers and then find the score for each annotator.\n",
    "    # k=(p_0 - p_e)/(1 - p_e) where p_0 is empirical probability and p_e is expected agreement.\n",
    "    # p_0 = num in agreement/ total\n",
    "    # p_e = p_correct + p_incorrect \n",
    "\n",
    "\n",
    "#nyt_stance work\n",
    "\n",
    "nyt_pair_dict ={}\n",
    "for nyt in nyt_stance:\n",
    "    \n",
    "    #Creat a confusion matrix for each pair of annotators\n",
    "    for pair in itertools.combinations(list(nyt.columns[1:]),2):\n",
    "        #print(pair)\n",
    "        cm = confusion_matrix(nyt[pair[0]],nyt[pair[1]])\n",
    "        #print(cm)\n",
    "\n",
    "        # Find number of rows in df to equal the total count\n",
    "        total = len(nyt.text)\n",
    "\n",
    "        #Find p0   \n",
    "        p0 = sum(cm[m][m] for m in range(len(cm)))/ total\n",
    "        #print('p0 = ', p0)\n",
    "\n",
    "        #Find pe\n",
    "        #pe = p of each class sum verticle/total * each class sum horizontal/total\n",
    "        pe = 0\n",
    "        for col in range(len(cm)):\n",
    "            pe += sum(cm[m][col] for m in range(len(cm)))*sum(cm[col][m] for m in range(len(cm)))\n",
    "\n",
    "        pe = pe/(total*total)\n",
    "        #print('pe = ', pe)\n",
    "\n",
    "        #Calculate Cohen's Kappa k=(p_0 - p_e)/(1 - p_e)\n",
    "        k = (p0 - pe) / (1 - pe)\n",
    "        #print('k = ',k)\n",
    "        \n",
    "        #Add the annotator pair and their Cohen's Kappa value to the dictionary\n",
    "        nyt_pair_dict[pair] = k\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894c588",
   "metadata": {},
   "source": [
    "Cohen's Kappa values for nyt_stance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30fa2ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('annotation_64', 'annotation_60'): 0.4766392841425847, ('annotation_64', 'annotation_61'): 0.37361510053344266, ('annotation_64', 'annotation_63'): 0.22998553963454713, ('annotation_60', 'annotation_61'): 0.4495505617977528, ('annotation_60', 'annotation_63'): 0.3249869406233677, ('annotation_61', 'annotation_63'): 0.3003073010490623, ('annotation_34', 'annotation_5'): 0.26157741130138196, ('annotation_34', 'annotation_20'): 0.3498383779018513, ('annotation_34', 'annotation_4'): 0.5355299722111949, ('annotation_5', 'annotation_20'): 0.30353430353430355, ('annotation_5', 'annotation_4'): 0.3226017918275184, ('annotation_20', 'annotation_4'): 0.37449258247841166, ('annotation_7', 'annotation_8'): -0.0043363965218954316, ('annotation_7', 'annotation_9'): 0.2823912756860603, ('annotation_7', 'annotation_78'): 0.5118937287611987, ('annotation_7', 'annotation_62'): 0.44581280788177335, ('annotation_8', 'annotation_9'): -0.0033332587637860444, ('annotation_8', 'annotation_78'): 0.0028331139714903968, ('annotation_8', 'annotation_62'): 0.0025661050987392615, ('annotation_9', 'annotation_78'): 0.22663448881088202, ('annotation_9', 'annotation_62'): 0.24590835459064933, ('annotation_78', 'annotation_62'): 0.5237416807441027}\n"
     ]
    }
   ],
   "source": [
    "#annotator pair Cohen's Kappa values for nyt_stance data\n",
    "print(nyt_pair_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c030f10b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Iterate through the complete list of annotators in all three nyt_stance csvs to\n",
    "#calculate each annotator's score\n",
    "#which is the average kappa score for that annotator in all the annotator pairs.  \n",
    "\n",
    "nyt_annotator_dict ={}\n",
    "\n",
    "for nyt in nyt_stance:\n",
    "    for annotator in list(nyt.columns[1:]):\n",
    "        #find the occurance of the annotator in the dictionary\n",
    "        k =0\n",
    "        counter = 0\n",
    "        for pair in nyt_pair_dict.keys():\n",
    "            if annotator in pair:\n",
    "                k += nyt_pair_dict[pair]\n",
    "                counter +=1\n",
    "        score = k/counter\n",
    "        nyt_annotator_dict[annotator] = score    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be27748c",
   "metadata": {},
   "source": [
    "Annotator Scores (average k) for nyt_stance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35d7862f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotation_64': 0.3600799747701915, 'annotation_60': 0.41705892885456836, 'annotation_61': 0.37449098779341927, 'annotation_63': 0.285093260435659, 'annotation_34': 0.38231525380480935, 'annotation_5': 0.29590450222106796, 'annotation_20': 0.34262175463818884, 'annotation_4': 0.41087478217237505, 'annotation_7': 0.3089403539517842, 'annotation_8': -0.0005676090538629544, 'annotation_9': 0.1879002150809514, 'annotation_78': 0.31627575307191846, 'annotation_62': 0.30450723707881616}\n"
     ]
    }
   ],
   "source": [
    "print(nyt_annotator_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db73d4a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#twitter_stance work\n",
    "\n",
    "twitter_pair_dict ={}\n",
    "for twit in twitter_stance:\n",
    "    \n",
    "    #Creat a confusion matrix for each pair of annotators\n",
    "    for pair in itertools.combinations(list(twit.columns[1:]),2):\n",
    "        #print(pair)\n",
    "        cm = confusion_matrix(twit[pair[0]],twit[pair[1]])\n",
    "        #print(cm)\n",
    "\n",
    "        # Find number of rows in df to equal the total count\n",
    "        total = len(twit.text)\n",
    "\n",
    "        #Find p0   \n",
    "        p0 = sum(cm[m][m] for m in range(len(cm)))/ total\n",
    "        #print('p0 = ', p0)\n",
    "\n",
    "        #Find pe\n",
    "        #pe = p of each class sum verticle/total * each class sum horizontal/total\n",
    "        pe = 0\n",
    "        for col in range(len(cm)):\n",
    "            pe += sum(cm[m][col] for m in range(len(cm)))*sum(cm[col][m] for m in range(len(cm)))\n",
    "\n",
    "        pe = pe/(total*total)\n",
    "        #print('pe = ', pe)\n",
    "\n",
    "        #Calculate Cohen's Kappa k=(p_0 - p_e)/(1 - p_e)\n",
    "        k = (p0 - pe) / (1 - pe)\n",
    "        #print('k = ',k)\n",
    "        \n",
    "        #Add the annotator pair and their Cohen's Kappa value to the dictionary\n",
    "        twitter_pair_dict[pair] = k\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd654ce7",
   "metadata": {},
   "source": [
    "Cohen's Kappa values for twitter_stance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43a034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('annotation_32', 'annotation_33'): 0.2534050781906845, ('annotation_32', 'annotation_35'): 0.4085410679676536, ('annotation_32', 'annotation_17'): 0.23917483660130712, ('annotation_33', 'annotation_35'): 0.3273542600896861, ('annotation_33', 'annotation_17'): 0.39112611526404634, ('annotation_35', 'annotation_17'): 0.4136460554371002, ('annotation_26', 'annotation_37'): 0.14795244385733158, ('annotation_26', 'annotation_38'): 0.2274502447260262, ('annotation_26', 'annotation_39'): 0.16167664670658682, ('annotation_37', 'annotation_38'): 0.31476016605812035, ('annotation_37', 'annotation_39'): 0.4467213114754098, ('annotation_38', 'annotation_39'): 0.28344746951728744, ('annotation_113', 'annotation_114'): 0.23612454070779346, ('annotation_113', 'annotation_115'): 0.23195876288659786, ('annotation_113', 'annotation_116'): 0.24873096446700513, ('annotation_114', 'annotation_115'): 0.16709511568123395, ('annotation_114', 'annotation_116'): 0.2042306723747167, ('annotation_115', 'annotation_116'): 0.27222222222222225}\n"
     ]
    }
   ],
   "source": [
    "print(twitter_pair_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73387c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through the complete list of annotators in all three nyt_stance csvs to\n",
    "#calculate each annotator's score\n",
    "#which is the average kappa score for that annotator in all the annotator pairs.  \n",
    "\n",
    "twitter_annotator_dict ={}\n",
    "\n",
    "for twit in twitter_stance:\n",
    "    for annotator in list(twit.columns[1:]):\n",
    "        #find the occurance of the annotator in the dictionary\n",
    "        k =0\n",
    "        counter = 0\n",
    "        for pair in twitter_pair_dict.keys():\n",
    "            if annotator in pair:\n",
    "                k += twitter_pair_dict[pair]\n",
    "                counter +=1\n",
    "        score = k/counter\n",
    "        twitter_annotator_dict[annotator] = score    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b3ab0",
   "metadata": {},
   "source": [
    "Annotator Scores (average k) for twitter_stance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37ff7145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotation_32': 0.3003736609198817, 'annotation_33': 0.323961817848139, 'annotation_35': 0.3831804611648133, 'annotation_17': 0.34798233576748455, 'annotation_26': 0.1790264450966482, 'annotation_37': 0.3031446404636206, 'annotation_38': 0.27521929343381135, 'annotation_39': 0.29728180923309466, 'annotation_113': 0.23893808935379882, 'annotation_114': 0.202483442921248, 'annotation_115': 0.22375870026335135, 'annotation_116': 0.2417279530213147}\n"
     ]
    }
   ],
   "source": [
    "print(twitter_annotator_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ca290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assemble the Dataset\n",
    "#    1. Assign a final label to each text, according to the following logic: \n",
    "#        - First, eliminate any labels for annotators whose average kappa score is less \n",
    "#        than 0.2 (unreliable annotators) \n",
    "#        - Second, assign the final label to each text as the most frequent label among \n",
    "#        the remainiing annotators \n",
    "#        - If there are ties (the same number of annotators for different labels), \n",
    "#        use the label with higher-reliability annotators (higher kappa scores on average) \n",
    "#    2. Combine all of the text/label pairs for the PRIMARY dataset into a single CSV file, \n",
    "#    with the columns \"text\" and \"label\" \n",
    "#    3. Combine all of the text/label pairs for the SECONDARY dataset into a single CSV file, \n",
    "#    with the columns \"text\" and \"label\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "376288ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, eliminate any labels for annotators whose average kappa score is less \n",
    "#than 0.2 (unreliable annotators) \n",
    "\n",
    "#nyt_stance\n",
    "for annotator,score in nyt_annotator_dict.items():\n",
    "    if score < 0.2:\n",
    "        for nyt in nyt_stance:\n",
    "            if annotator in list(nyt.columns[1:]):\n",
    "                del nyt[annotator]\n",
    "                \n",
    "                        \n",
    "#twitter_stance\n",
    "for annotator,score in twitter_annotator_dict.items():\n",
    "    if score < 0.2:\n",
    "        for twit in twitter_stance:\n",
    "            if annotator in list(twit.columns[1:]):\n",
    "                del twit[annotator]\n",
    "\n",
    "#Check that only annotators at score of 0.2 or above remain\n",
    "#for twit in twitter_stance:\n",
    "#    for annotator in list(twit.columns[1:]):\n",
    "#        print(annotator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d280caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(votes):\n",
    "    d={}\n",
    "    for e in votes:\n",
    "        d[e]=d.get(e,0)+1\n",
    "    \n",
    "    answers = sorted([(k,v,) for k,v in d.items()],key=lambda x:-x[1])\n",
    "    if len(answers)==1:\n",
    "        return answers[0][0]\n",
    "    if answers[0][1]> answers[1][1]:\n",
    "        return answers[0][0]\n",
    "    majority=answers[0][1]\n",
    "    ties=[]\n",
    "    for ans in answers:\n",
    "        if ans[1] ==majority: #if votes are the same as currently labeled majority\n",
    "            ties.append(ans[0]) #ans[0] is one of tied labelS\n",
    "        else:\n",
    "            break\n",
    "    for vote in votes:\n",
    "        if vote in ties:\n",
    "            return vote #returns the first vote that matches in ties, which is also the vote of the highest scoring annotator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5346dc45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Second, assign the final label to each text as the most frequent label among \n",
    "# the remainiing annotators \n",
    "with open(\"secondary_labels.csv\",'w') as secondary_labels:\n",
    "    csvwriter = csv.writer(secondary_labels)\n",
    "    csvwriter.writerow([\"text\",\"label\"])\n",
    "    \n",
    "    #nyt_stance\n",
    "    for nyt in nyt_stance:\n",
    "        #put annotators in order of highest score \n",
    "        #to be able to use mode later and select the one with the highest score\n",
    "        #(b/c mode returns the first most frequent mode in the case of a tie, we need annotators in order of highest score)\n",
    "        annotator_tup =[]\n",
    "        labels = []\n",
    "        for annotator in list(nyt.columns[1:]):\n",
    "            annotator_tup.append([annotator,nyt_annotator_dict[annotator]])   \n",
    "\n",
    "        #Reorder annotators in score order\n",
    "        newOrder = ['text']+[ ann for ann,other in sorted(annotator_tup,key=lambda x:-x[1]) ]\n",
    "        nyt_new=nyt[newOrder]\n",
    "\n",
    "        #iterate through rows to find count and determine labels\n",
    "        #call majority_vote function to determine final vote on label\n",
    "        for row in nyt_new.itertuples():\n",
    "            #write to file\n",
    "            #    2. Combine all of the text/label pairs for the PRIMARY dataset into a single CSV file, \n",
    "            #    with the columns \"text\" and \"label\" \n",
    "            csvwriter.writerow([row[1],majority_vote(row[2:])])\n",
    "     \n",
    "                        \n",
    "#twitter_stance\n",
    "\n",
    "with open(\"primary_labels.csv\",'w') as primary_labels:\n",
    "    csvwriter = csv.writer(primary_labels)\n",
    "    csvwriter.writerow([\"text\",\"label\"])\n",
    "    \n",
    "    #twitter_stance\n",
    "    for twit in twitter_stance:\n",
    "        #put annotators in order of highest score \n",
    "        #to be able to use mode later and select the one with the highest score\n",
    "        #(b/c mode returns the first most frequent mode in the case of a tie, we need annotators in order of highest score)\n",
    "        annotator_tup =[]\n",
    "        labels = []\n",
    "        for annotator in list(twit.columns[1:]):\n",
    "            annotator_tup.append([annotator,twitter_annotator_dict[annotator]])   \n",
    "\n",
    "        #Reorder annotators in score order\n",
    "        newOrder = ['text']+[ ann for ann,other in sorted(annotator_tup,key=lambda x:-x[1]) ]\n",
    "        twitter_new=twit[newOrder]\n",
    "\n",
    "        #iterate through rows to find count and determine labels\n",
    "        #call majority_vote function to determine final vote on label\n",
    "        for row in twitter_new.itertuples():\n",
    "            #write to file\n",
    "            #    3. Combine all of the text/label pairs for the SECONDARY dataset into a single CSV file, \n",
    "            #    with the columns \"text\" and \"label\n",
    "            csvwriter.writerow([row[1],majority_vote(row[2:])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
